\documentclass[letterpaper, 10 pt, conference]{IEEEconf}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[style=ieee]{biblatex}
\usepackage{amsmath, amssymb, xcolor, tikz, pgfplots}

\newcommand{\todo}[1]{{\color{red}#1}}

\title{\LARGE \bf
A Pipeline to Assemble Near-Accident Footage Datasets
}

\author{
         Ben Upenieks, Chaitanya Varier,\\
         Curtis Duy Kha Phan, Jack David Roberts Williamson,\\
         Nicholas Geofroy, Tony Meng, Vincent-Olivier Roch\\
         University of Waterloo\\
         \\
         \tt\small ben.upenieks@uwaterloo.ca, cvarier@uwaterloo.ca,
         \\ \tt\small cdkphan@uwaterloo.ca, jdrwilli@uwaterloo.ca,
         \\ \tt\small nicholas.geofroy@uwaterloo.ca, c24meng@uwaterloo.ca, vroch@uwaterloo.ca
}

\bibliography{sources}
\begin{document}

\maketitle
\thispagestyle{empty}
\pagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}

\todo{Write the abstract}

\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{INTRODUCTION}

In the advent of connected vehicles and autonomous transportation, equipping consumer vehicles with the necessary equipment to facilitate high-end automated collision avoidance systems can be prohibitively expensive.
Technologies such as Radar, LIDAR and high-end cameras that are typically used for collision prediction are likely too expensive for most consumers and might not easily be affixed to their vehicles (maybe not true).
We note that front-facing dash-cams have become increasingly affordable and prevalent as a means to capture a driverâ€™s perspective leading up to the event of a potential collision.
This has led to the creation of many online communities to share such videos.
We propose that this egocentric dash-cam video stream can be leveraged by computer vision systems to act as an affordable and commonplace sensor for automated collision prediction. 

In this paper we present a software pipeline to facilitate the collection, processing and annotation of egocentric dash-cam videos from various online video repositories to produce datasets that can be used to train deep dash-cam collision prediction models.
We aim to generate datasets that are not constrained to any regions or countries but rather provide location-agnostic data that is representative of general, global road and vehicle conditions.
These datasets will also be collision-oriented as the majority of these videos contain collisions for people's entertainment.
Current autonomous vehicle data collection techniques typically require astronomically expensive hardware and equipment and, consequently, are rarely involved in collisions and intentionally not put in high risk environments that may lead to a collision.
This is the data we hope to capture by taking advantage of existing videos of non-artificial collisions.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{BACKGROUND / PRELIMINARY}
\todo{write the background / preliminary} \\
introducing basic ideas to readers. why is the annotation pipeline important (how was the annotation toolbox developed) - use separate subsections

\todo{Work in progress}

Dash-cams are cheap video cameras that can be mounted a car's dashboard or windshield to continuously save a recording of a driver's perspective to an internal memory card.
Exceptional events recorded by the dashcam such as collisions and crashes are often uploaded and shared to popular social media websites and video repositories such as Reddit, Youtube, and Imgur and are typically tagged with a closely related set of key terms.
The pipeline uses web-scraping techniques to fetch the video data from these websites, along with a set of video metadata, describing the video's contents.
We use this data, in combination with the manually annotated data in order to create the collision dataset.
\todo{Not sure what else to put here}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{RELATED WORK}

Chan et al. \cite{chan2016anticipating} approach the same problem of collision prediction via egocentric dash-cam videos. They propose a novel Dynamic-Spatial-Attention Recurrent Neural Network that distributes attention to localized and tracked vehicles within the video and models temporal dependencies to predict the earliest frame of a potential impending collision. Released with their paper is a dataset of 678 dash-cam videos capturing areas in Taiwan. Each video is annotated with vehicle tracking bounding boxes, the vehicles that were involved in the collision and the frame of the collision. We hope to allow researchers to expand on this dataset with location-agnostic data and similar annotations.



\subsection{Dash-cams}%
\label{sub:dash_cams}







%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{METHODOLOGY}

\todo{Write the METHODOLOGY}
\begin{itemize}
  \item Major pipeline
  \item Presenting a graph or figure of the pipeline architecture
  \begin{itemize}
    \item pre-processing
    \item Tracking we can mention how prepare to solve the tracking problem (challenge and future work)
    \item Blurring (tracking and blurring of vehicle plates and faces)
  \end{itemize}
\end{itemize}
\subsection{Video Preprocessing}
\subsection{Automatic Annotation}
\subsection{Object Detection \& Tracking}
\subsection{Blurring}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{EXPERIMENT}
- present results of our data, reference the Kitti dataset and how they presented their own data (histogram of object classes, velocity, acceleration, etc)
- the major contribution we have is the histogram of accident type
- Histogram of data
- Usage of our data (applications) - not a major section, just describe potential in preventing/predicting accidents and their importance


\todo{Write the EXPERIMENT SECTION (analyzing data)}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{CONCLUSION}

\todo{Write the conclusion}
A conclusion section is not required. Although a conclusion may review the main points of the paper, do not replicate the abstract as the conclusion. A conclusion might elaborate on the importance of the work or suggest applications and extensions.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{FUTURE WORK}

\todo{Write the future work ideas}

\addtolength{\textheight}{-12cm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{APPENDIX}

\todo{Write the appendix}

\begin{center}
\begin{tikzpicture}
\begin{axis}[
  title={Example histogram},
  xlabel={Classes},
  ylabel={$\textup{Normal}(\mu=0, \sigma=1)$}
]
\addplot[fill, ybar] table [x=X, y=Y, col sep=comma] {example.csv};
\end{axis}
\end{tikzpicture}
\end{center}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\nocite{*}
\printbibliography

\end{document}
